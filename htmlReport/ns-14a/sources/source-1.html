<!--

    Copyright © 2016-2026 The Thingsboard Authors

    Licensed under the Apache License, Version 2.0 (the "License");
    you may not use this file except in compliance with the License.
    You may obtain a copy of the License at

        http://www.apache.org/licenses/LICENSE-2.0

    Unless required by applicable law or agreed to in writing, software
    distributed under the License is distributed on an "AS IS" BASIS,
    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
    See the License for the specific language governing permissions and
    limitations under the License.

-->



<!DOCTYPE html>
<html id="htmlId">
<head>
  <meta http-equiv="Content-Type" content="text/html;charset=UTF-8"> 
  <title>Coverage Report > KafkaAdmin</title>
  <style type="text/css">
    @import "../../css/coverage.css";
    @import "../../css/idea.min.css";
  </style>
  <script type="text/javascript" src="../../js/highlight.min.js"></script>
  <script type="text/javascript" src="../../js/highlightjs-line-numbers.min.js"></script>
</head>

<body>
<div class="content">
<div class="breadCrumbs">
Current scope:     <a href="../../index.html">all classes</a>
    <span class="separator">|</span>
    <a href="../index.html">org.thingsboard.server.queue.kafka</a>
</div>

<h1>Coverage Summary for Class: KafkaAdmin (org.thingsboard.server.queue.kafka)</h1>

<table class="coverageStats">
<tr>
  <th class="name">Class</th>
<th class="coverageStat 
">
  Class, %
</th>
<th class="coverageStat 
">
  Method, %
</th>
<th class="coverageStat 
">
  Branch, %
</th>
<th class="coverageStat 
">
  Line, %
</th>
</tr>
<tr>
  <td class="name">KafkaAdmin</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/1)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/19)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/32)
  </span>
</td>
<td class="coverageStat">
  <span class="percent">
    0%
  </span>
  <span class="absValue">
    (0/106)
  </span>
</td>
</tr>

</table>

<br/>
<br/>


<pre>
<code class="sourceCode" id="sourceCode">&nbsp;/**
&nbsp; * Copyright © 2016-2026 The Thingsboard Authors
&nbsp; *
&nbsp; * Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);
&nbsp; * you may not use this file except in compliance with the License.
&nbsp; * You may obtain a copy of the License at
&nbsp; *
&nbsp; *     http://www.apache.org/licenses/LICENSE-2.0
&nbsp; *
&nbsp; * Unless required by applicable law or agreed to in writing, software
&nbsp; * distributed under the License is distributed on an &quot;AS IS&quot; BASIS,
&nbsp; * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
&nbsp; * See the License for the specific language governing permissions and
&nbsp; * limitations under the License.
&nbsp; */
&nbsp;package org.thingsboard.server.queue.kafka;
&nbsp;
&nbsp;import jakarta.annotation.PreDestroy;
&nbsp;import lombok.SneakyThrows;
&nbsp;import lombok.extern.slf4j.Slf4j;
&nbsp;import org.apache.commons.lang3.concurrent.ConcurrentException;
&nbsp;import org.apache.commons.lang3.concurrent.LazyInitializer;
&nbsp;import org.apache.kafka.clients.admin.AdminClient;
&nbsp;import org.apache.kafka.clients.admin.ListOffsetsResult;
&nbsp;import org.apache.kafka.clients.admin.NewTopic;
&nbsp;import org.apache.kafka.clients.admin.OffsetSpec;
&nbsp;import org.apache.kafka.clients.admin.TopicDescription;
&nbsp;import org.apache.kafka.clients.consumer.OffsetAndMetadata;
&nbsp;import org.apache.kafka.common.TopicPartition;
&nbsp;import org.apache.kafka.common.errors.TopicExistsException;
&nbsp;import org.springframework.beans.factory.annotation.Value;
&nbsp;import org.springframework.context.annotation.Lazy;
&nbsp;import org.springframework.stereotype.Component;
&nbsp;import org.thingsboard.common.util.CachedValue;
&nbsp;import org.thingsboard.server.queue.util.TbKafkaComponent;
&nbsp;
&nbsp;import java.util.Collections;
&nbsp;import java.util.HashMap;
&nbsp;import java.util.List;
&nbsp;import java.util.Map;
&nbsp;import java.util.Optional;
&nbsp;import java.util.Set;
&nbsp;import java.util.concurrent.ConcurrentHashMap;
&nbsp;import java.util.concurrent.ExecutionException;
&nbsp;import java.util.concurrent.TimeUnit;
&nbsp;import java.util.concurrent.TimeoutException;
&nbsp;import java.util.stream.Collectors;
&nbsp;
&nbsp;@TbKafkaComponent
&nbsp;@Component
<b class="nc">&nbsp;@Slf4j</b>
&nbsp;public class KafkaAdmin {
&nbsp;
&nbsp;    /*
&nbsp;     * TODO: Get rid of per consumer/producer TbKafkaAdmin,
&nbsp;     *  use single KafkaAdmin instance that accepts topicConfigs.
&nbsp;     * */
&nbsp;
&nbsp;    private final TbKafkaSettings settings;
&nbsp;
&nbsp;    private final LazyInitializer&lt;AdminClient&gt; adminClient;
&nbsp;    private final CachedValue&lt;Set&lt;String&gt;&gt; topics;
&nbsp;
&nbsp;    public KafkaAdmin(@Lazy TbKafkaSettings settings,
&nbsp;                      @Value(&quot;${queue.kafka.topics_cache_ttl_ms:300000}&quot;)
<b class="nc">&nbsp;                      int topicsCacheTtlMs) {</b>
<b class="nc">&nbsp;        this.settings = settings;</b>
<b class="nc">&nbsp;        this.adminClient = LazyInitializer.&lt;AdminClient&gt;builder()</b>
<b class="nc">&nbsp;                .setInitializer(() -&gt; AdminClient.create(settings.toAdminProps()))</b>
<b class="nc">&nbsp;                .get();</b>
<b class="nc">&nbsp;        this.topics = new CachedValue&lt;&gt;(() -&gt; {</b>
<b class="nc">&nbsp;            Set&lt;String&gt; topics = ConcurrentHashMap.newKeySet();</b>
<b class="nc">&nbsp;            topics.addAll(listTopics());</b>
<b class="nc">&nbsp;            return topics;</b>
&nbsp;        }, topicsCacheTtlMs);
&nbsp;    }
&nbsp;
&nbsp;    public void createTopicIfNotExists(String topic, Map&lt;String, String&gt; properties, boolean force) {
<b class="nc">&nbsp;        Set&lt;String&gt; topics = getTopics();</b>
<b class="nc">&nbsp;        if (!force &amp;&amp; topics.contains(topic)) {</b>
<b class="nc">&nbsp;            log.trace(&quot;Topic {} already present in cache&quot;, topic);</b>
&nbsp;            return;
&nbsp;        }
&nbsp;
<b class="nc">&nbsp;        log.debug(&quot;Creating topic {} with properties {}&quot;, topic, properties);</b>
<b class="nc">&nbsp;        String numPartitionsStr = properties.remove(TbKafkaTopicConfigs.NUM_PARTITIONS_SETTING);</b>
<b class="nc">&nbsp;        int partitions = numPartitionsStr != null ? Integer.parseInt(numPartitionsStr) : 1;</b>
<b class="nc">&nbsp;        NewTopic newTopic = new NewTopic(topic, partitions, settings.getReplicationFactor()).configs(properties);</b>
&nbsp;
&nbsp;        try {
<b class="nc">&nbsp;            getClient().createTopics(List.of(newTopic)).all().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
<b class="nc">&nbsp;            topics.add(topic);</b>
&nbsp;        } catch (ExecutionException ee) {
<b class="nc">&nbsp;            log.trace(&quot;Failed to create topic {} with properties {}&quot;, topic, properties, ee);</b>
<b class="nc">&nbsp;            if (ee.getCause() instanceof TopicExistsException) {</b>
&nbsp;                //do nothing
&nbsp;            } else {
<b class="nc">&nbsp;                log.warn(&quot;[{}] Failed to create topic&quot;, topic, ee);</b>
<b class="nc">&nbsp;                throw new RuntimeException(ee);</b>
&nbsp;            }
&nbsp;        } catch (Exception e) {
<b class="nc">&nbsp;            log.warn(&quot;[{}] Failed to create topic&quot;, topic, e);</b>
<b class="nc">&nbsp;            throw new RuntimeException(e);</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    public void deleteTopic(String topic) {
<b class="nc">&nbsp;        log.debug(&quot;Deleting topic {}&quot;, topic);</b>
&nbsp;        try {
<b class="nc">&nbsp;            getClient().deleteTopics(List.of(topic)).all().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
&nbsp;        } catch (Exception e) {
<b class="nc">&nbsp;            log.error(&quot;Failed to delete kafka topic [{}].&quot;, topic, e);</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    private Set&lt;String&gt; getTopics() {
<b class="nc">&nbsp;        return topics.get();</b>
&nbsp;    }
&nbsp;
&nbsp;    public Set&lt;String&gt; listTopics() {
&nbsp;        try {
<b class="nc">&nbsp;            Set&lt;String&gt; topics = getClient().listTopics().names().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
<b class="nc">&nbsp;            log.trace(&quot;Listed topics: {}&quot;, topics);</b>
<b class="nc">&nbsp;            return topics;</b>
&nbsp;        } catch (Exception e) {
<b class="nc">&nbsp;            log.error(&quot;Failed to get all topics.&quot;, e);</b>
<b class="nc">&nbsp;            return Collections.emptySet();</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    public Map&lt;String, Long&gt; getTotalLagForGroupsBulk(Set&lt;String&gt; groupIds) {
<b class="nc">&nbsp;        Map&lt;String, Long&gt; result = new HashMap&lt;&gt;();</b>
<b class="nc">&nbsp;        for (String groupId : groupIds) {</b>
<b class="nc">&nbsp;            result.put(groupId, getTotalConsumerGroupLag(groupId));</b>
&nbsp;        }
<b class="nc">&nbsp;        return result;</b>
&nbsp;    }
&nbsp;
&nbsp;    public long getTotalConsumerGroupLag(String groupId) {
&nbsp;        try {
<b class="nc">&nbsp;            Map&lt;TopicPartition, OffsetAndMetadata&gt; committedOffsets = getConsumerGroupOffsets(groupId);</b>
<b class="nc">&nbsp;            if (committedOffsets.isEmpty()) {</b>
<b class="nc">&nbsp;                return 0L;</b>
&nbsp;            }
&nbsp;
<b class="nc">&nbsp;            Map&lt;TopicPartition, OffsetSpec&gt; latestOffsetsSpec = committedOffsets.keySet().stream()</b>
<b class="nc">&nbsp;                    .collect(Collectors.toMap(tp -&gt; tp, tp -&gt; OffsetSpec.latest()));</b>
&nbsp;
<b class="nc">&nbsp;            Map&lt;TopicPartition, ListOffsetsResult.ListOffsetsResultInfo&gt; endOffsets =</b>
<b class="nc">&nbsp;                    getClient().listOffsets(latestOffsetsSpec).all().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
&nbsp;
<b class="nc">&nbsp;            return committedOffsets.entrySet().stream()</b>
<b class="nc">&nbsp;                    .mapToLong(entry -&gt; {</b>
<b class="nc">&nbsp;                        TopicPartition tp = entry.getKey();</b>
<b class="nc">&nbsp;                        long committed = entry.getValue().offset();</b>
<b class="nc">&nbsp;                        long end = endOffsets.getOrDefault(tp,</b>
<b class="nc">&nbsp;                                new ListOffsetsResult.ListOffsetsResultInfo(0L, 0L, Optional.empty())).offset();</b>
<b class="nc">&nbsp;                        return end - committed;</b>
<b class="nc">&nbsp;                    }).sum();</b>
&nbsp;
&nbsp;        } catch (Exception e) {
<b class="nc">&nbsp;            log.error(&quot;Failed to get total lag for consumer group: {}&quot;, groupId, e);</b>
<b class="nc">&nbsp;            return 0L;</b>
&nbsp;        }
&nbsp;    }
&nbsp;
<b class="nc">&nbsp;    @SneakyThrows</b>
&nbsp;    public Map&lt;TopicPartition, OffsetAndMetadata&gt; getConsumerGroupOffsets(String groupId) {
<b class="nc">&nbsp;        return getClient().listConsumerGroupOffsets(groupId).partitionsToOffsetAndMetadata().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
&nbsp;    }
&nbsp;
&nbsp;    /**
&nbsp;     * Sync offsets from a fat group to a single-partition group
&nbsp;     * Migration back from single-partition consumer to a fat group is not supported
&nbsp;     * TODO: The best possible approach to synchronize the offsets is to do the synchronization as a part of the save Queue parameters with stop all consumers
&nbsp;     * */
&nbsp;    public void syncOffsets(String fatGroupId, String newGroupId, Integer partitionId) {
&nbsp;        try {
<b class="nc">&nbsp;            log.info(&quot;syncOffsets [{}][{}][{}]&quot;, fatGroupId, newGroupId, partitionId);</b>
<b class="nc">&nbsp;            if (partitionId == null) {</b>
&nbsp;                return;
&nbsp;            }
<b class="nc">&nbsp;            syncOffsetsUnsafe(fatGroupId, newGroupId, &quot;.&quot; + partitionId);</b>
&nbsp;        } catch (Exception e) {
<b class="nc">&nbsp;            log.warn(&quot;Failed to syncOffsets from {} to {} partitionId {}&quot;, fatGroupId, newGroupId, partitionId, e);</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    public void syncOffsetsUnsafe(String fatGroupId, String newGroupId, String topicSuffix) throws ExecutionException, InterruptedException, TimeoutException {
<b class="nc">&nbsp;        Map&lt;TopicPartition, OffsetAndMetadata&gt; oldOffsets = getConsumerGroupOffsets(fatGroupId);</b>
<b class="nc">&nbsp;        if (oldOffsets.isEmpty()) {</b>
&nbsp;            return;
&nbsp;        }
&nbsp;
<b class="nc">&nbsp;        for (var consumerOffset : oldOffsets.entrySet()) {</b>
<b class="nc">&nbsp;            var tp = consumerOffset.getKey();</b>
<b class="nc">&nbsp;            if (!tp.topic().endsWith(topicSuffix)) {</b>
&nbsp;                continue;
&nbsp;            }
<b class="nc">&nbsp;            var om = consumerOffset.getValue();</b>
<b class="nc">&nbsp;            Map&lt;TopicPartition, OffsetAndMetadata&gt; newOffsets = getConsumerGroupOffsets(newGroupId);</b>
&nbsp;
<b class="nc">&nbsp;            var existingOffset = newOffsets.get(tp);</b>
<b class="nc">&nbsp;            if (existingOffset == null) {</b>
<b class="nc">&nbsp;                log.info(&quot;[{}] topic offset does not exists in the new node group {}, all found offsets {}&quot;, tp, newGroupId, newOffsets);</b>
<b class="nc">&nbsp;            } else if (existingOffset.offset() &gt;= om.offset()) {</b>
<b class="nc">&nbsp;                log.info(&quot;[{}] topic offset {} &gt;= than old node group offset {}&quot;, tp, existingOffset.offset(), om.offset());</b>
&nbsp;                break;
&nbsp;            } else {
<b class="nc">&nbsp;                log.info(&quot;[{}] SHOULD alter topic offset [{}] less than old node group offset [{}]&quot;, tp, existingOffset.offset(), om.offset());</b>
&nbsp;            }
<b class="nc">&nbsp;            getClient().alterConsumerGroupOffsets(newGroupId, Map.of(tp, om)).all().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
<b class="nc">&nbsp;            log.info(&quot;[{}] altered new consumer groupId {}&quot;, tp, newGroupId);</b>
&nbsp;            break;
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    public boolean isTopicEmpty(String topic) {
<b class="nc">&nbsp;        return areAllTopicsEmpty(Set.of(topic));</b>
&nbsp;    }
&nbsp;
&nbsp;    public boolean areAllTopicsEmpty(Set&lt;String&gt; topics) {
&nbsp;        try {
<b class="nc">&nbsp;            List&lt;String&gt; existingTopics = getTopics().stream().filter(topics::contains).toList();</b>
<b class="nc">&nbsp;            if (existingTopics.isEmpty()) {</b>
<b class="nc">&nbsp;                return true;</b>
&nbsp;            }
&nbsp;
<b class="nc">&nbsp;            List&lt;TopicPartition&gt; allPartitions = getClient().describeTopics(existingTopics).allTopicNames().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS)</b>
<b class="nc">&nbsp;                    .entrySet().stream()</b>
<b class="nc">&nbsp;                    .flatMap(entry -&gt; {</b>
<b class="nc">&nbsp;                        String topic = entry.getKey();</b>
<b class="nc">&nbsp;                        TopicDescription topicDescription = entry.getValue();</b>
<b class="nc">&nbsp;                        return topicDescription.partitions().stream().map(partitionInfo -&gt; new TopicPartition(topic, partitionInfo.partition()));</b>
&nbsp;                    })
<b class="nc">&nbsp;                    .toList();</b>
&nbsp;
<b class="nc">&nbsp;            Map&lt;TopicPartition, ListOffsetsResult.ListOffsetsResultInfo&gt; beginningOffsets = getClient().listOffsets(allPartitions.stream()</b>
<b class="nc">&nbsp;                    .collect(Collectors.toMap(partition -&gt; partition, partition -&gt; OffsetSpec.earliest()))).all().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
<b class="nc">&nbsp;            Map&lt;TopicPartition, ListOffsetsResult.ListOffsetsResultInfo&gt; endOffsets = getClient().listOffsets(allPartitions.stream()</b>
<b class="nc">&nbsp;                    .collect(Collectors.toMap(partition -&gt; partition, partition -&gt; OffsetSpec.latest()))).all().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
&nbsp;
<b class="nc">&nbsp;            for (TopicPartition partition : allPartitions) {</b>
<b class="nc">&nbsp;                long beginningOffset = beginningOffsets.get(partition).offset();</b>
<b class="nc">&nbsp;                long endOffset = endOffsets.get(partition).offset();</b>
&nbsp;
<b class="nc">&nbsp;                if (beginningOffset != endOffset) {</b>
<b class="nc">&nbsp;                    log.debug(&quot;Partition [{}] of topic [{}] is not empty. Returning false.&quot;, partition.partition(), partition.topic());</b>
<b class="nc">&nbsp;                    return false;</b>
&nbsp;                }
&nbsp;            }
<b class="nc">&nbsp;            return true;</b>
&nbsp;        } catch (Exception e) {
<b class="nc">&nbsp;            log.error(&quot;Failed to check if topics [{}] empty.&quot;, topics, e);</b>
<b class="nc">&nbsp;            return false;</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    public void deleteConsumerGroup(String consumerGroupId) {
&nbsp;        try {
<b class="nc">&nbsp;            getClient().deleteConsumerGroups(List.of(consumerGroupId)).all().get(settings.getRequestTimeoutMs(), TimeUnit.MILLISECONDS);</b>
&nbsp;        } catch (Exception e) {
<b class="nc">&nbsp;            log.warn(&quot;Failed to delete consumer group {}&quot;, consumerGroupId, e);</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    public AdminClient getClient() {
&nbsp;        try {
<b class="nc">&nbsp;            return adminClient.get();</b>
&nbsp;        } catch (ConcurrentException e) {
<b class="nc">&nbsp;            throw new RuntimeException(&quot;Failed to initialize Kafka admin client&quot;, e);</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;    @PreDestroy
&nbsp;    private void destroy() throws Exception {
<b class="nc">&nbsp;        if (adminClient.isInitialized()) {</b>
<b class="nc">&nbsp;            adminClient.get().close();</b>
&nbsp;        }
&nbsp;    }
&nbsp;
&nbsp;}
</code>
</pre>
</div>

<script type="text/javascript">
(function() {
    var msie = false, msie9 = false;
    /*@cc_on
      msie = true;
      @if (@_jscript_version >= 9)
        msie9 = true;
      @end
    @*/

    if (!msie || msie && msie9) {
      hljs.highlightAll()
      hljs.initLineNumbersOnLoad();
    }
})();
</script>

<div class="footer">
    
    <div style="float:right;">generated on 2026-02-07 20:03</div>
</div>
</body>
</html>
